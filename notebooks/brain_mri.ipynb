{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow training detailed here: https://www.kaggle.com/code/samuelcortinhas/case-study-u-net-from-scratch/notebook\n",
    "# command for copying in data from Downloads folder in home dir:\n",
    "# unzip ~/Downloads/archive.zip \"/lgg-mri-segmentation/*\" -d data/brain_mri/\n",
    "import cv2\n",
    "import random\n",
    "import typing as T\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from segmentation.utils.metrics import (\n",
    "    dice_coefficient_loss,\n",
    "    dice_coeffient,\n",
    "    jaccard_index,\n",
    ")\n",
    "from segmentation.models.attention_unet import attention_unet\n",
    "\n",
    "def set_seed(seed: int = random.randint(0, 1000000)):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/brain_mri\")\n",
    "mask_files = list(DATA_PATH.glob(\"lgg-mri-segmentation/kaggle_3m/*/*_mask*\"))\n",
    "mask_files = list(map(str, mask_files))\n",
    "training_files = [path.replace(\"_mask\", \"\") for path in mask_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 3\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for i in range(1,rows*cols+1):\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    rand_img = random.randint(0, len(training_files)-1)\n",
    "    img_path = training_files[rand_img]\n",
    "    msk_path = mask_files[rand_img]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    msk = cv2.imread(msk_path)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk, alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"filename\": training_files, 'mask' : mask_files})\n",
    "df_train, df_test = train_test_split(df, test_size=0.1)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2)\n",
    "\n",
    "print(\"Shape of Training Dataset: \", df_train.shape)\n",
    "print(\"Shape of Val Dataset: \", df_val.shape)\n",
    "print(\"Shape of Test Dataset: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image_and_binary_mask(image: np.ndarray, mask: np.ndarray) -> T.Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Scale an image and mask between 0 and 1. Binary 1 or 0 is applied to mask image.\n",
    "    \"\"\"\n",
    "    image = image / 255\n",
    "    mask = mask / 255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask < 0.5] = 0\n",
    "\n",
    "    return (image, mask)\n",
    "\n",
    "\n",
    "def training_generator(\n",
    "    df: pd.DataFrame, \n",
    "    generator_params: T.Dict[str, T.Any],\n",
    "    batch_size: int = 64, \n",
    "    image_color_mode=\"rgb\",\n",
    "    mask_color_mode=\"grayscale\",\n",
    "    image_save_prefix=\"image\",\n",
    "    mask_save_prefix=\"mask\",\n",
    "    save_to_dir=None,\n",
    "    target_size=(256,256),\n",
    "    seed=1,\n",
    "    ) -> T.Generator:\n",
    "        \"\"\"\n",
    "        Generator function that yields images and masks that have been modified based on the keras Image Generator's\n",
    "        parameters.\n",
    "        \"\"\"\n",
    "        image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(**generator_params)\n",
    "        mask_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(**generator_params)\n",
    "        \n",
    "        image_generator = image_data_generator.flow_from_dataframe(\n",
    "            df, \n",
    "            x_col=\"filename\", \n",
    "            class_mode=None, \n",
    "            color_mode=image_color_mode, \n",
    "            target_size=target_size, \n",
    "            batch_size=batch_size, \n",
    "            save_to_dir=save_to_dir, \n",
    "            save_prefix=image_save_prefix\n",
    "        )\n",
    "        mask_generator = mask_data_generator.flow_from_dataframe(\n",
    "            df,\n",
    "            x_col=\"mask\",\n",
    "            class_mode=None,\n",
    "            color_mode=mask_color_mode,\n",
    "            target_size=target_size, \n",
    "            batch_size=batch_size, \n",
    "            save_to_dir=save_to_dir, \n",
    "            save_prefix=mask_save_prefix\n",
    "        )\n",
    "\n",
    "        train_gen = zip(image_generator, mask_generator)\n",
    "        for (image, mask) in train_gen:\n",
    "            image, mask = scale_image_and_binary_mask(image, mask)\n",
    "            yield (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 1e-3\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 256\n",
    "\n",
    "IMAGE_GENERATOR_PARAMS = {\n",
    "    \"rotation_range\": 0.2,\n",
    "    \"width_shift_range\": 0.1,\n",
    "    \"height_shift_range\": 0.1,\n",
    "    \"shear_range\": 0.05,\n",
    "    \"zoom_range\": 0.05,\n",
    "    \"horizontal_flip\": True,\n",
    "    \"fill_mode\": \"nearest\"\n",
    "}\n",
    "\n",
    "train_generator = training_generator(\n",
    "    df_train,\n",
    "    IMAGE_GENERATOR_PARAMS,\n",
    "    BATCH_SIZE,\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    ")\n",
    "test_generator = training_generator(\n",
    "    df_test, {}, BATCH_SIZE, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=None,\n",
    "    amsgrad=False,\n",
    ")\n",
    "\n",
    "training_path = DATA_PATH.parent / \"training\"\n",
    "training_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    # Save training weights only for model that has highest accuracy on validation dataset\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        (training_path / \"unet_brain_mri_segmentation.hdf5\").as_posix(),\n",
    "        monitor=\"val_acc\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "    ),\n",
    "    # Stop training model after 5 epochs if the model accuracy doesn't improve.\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=5),\n",
    "    # Reduce learning rate if accuracy is not improving on training dataset.\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"acc\", factor=0.1, patience=3),\n",
    "    # Stop training process if we are returning NaN value in loss\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = attention_unet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), num_classes=1)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=dice_coefficient_loss,\n",
    "    metrics=[\"binary_accuracy\", jaccard_index, dice_coeffient],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(df_train) / BATCH_SIZE, \n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(df_val) / BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "211bf73c8563a1dbaf67c8565265b14b92bce91a8d3fc768f8d1bcc63fc9272a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('aerial-segmentation-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
