{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import typing as T\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, fbeta_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "# seed with some random number...\n",
    "random.seed(414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"../data/eurosat/2750\")\n",
    "category_counts = {category.name: 0 for category in DATA_PATH.glob(\"*\")}\n",
    "for category in category_counts.keys():\n",
    "    category_counts[category] = len(list((DATA_PATH / category).glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(category_counts)), list(category_counts.values()), align=\"center\")\n",
    "plt.xticks(range(len(category_counts)), list(category_counts.keys()), fontsize=12, rotation=40)\n",
    "plt.xlabel(\"Class Label\", fontsize=13)\n",
    "plt.ylabel(\"Class Size\", fontsize=13)\n",
    "plt.title(\"EUROSAT Class Distribution\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(category_counts: T.Dict[str, int] = category_counts) -> T.List[Path]:\n",
    "    return [DATA_PATH / c / (c + \"_\" + str(random.randint(0, 2000)) + \".jpg\") for c in category_counts.keys()]\n",
    "\n",
    "img_paths = get_random_images()\n",
    "img_paths += get_random_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(paths: T.List[Path]) -> None:\n",
    "    if len(paths) != 20:\n",
    "        raise ValueError(\"Paths list should only have 20 image paths.\")\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(20):\n",
    "        plt.subplot(4, 5, i + 1, xticks=[], yticks=[])\n",
    "        image = PIL.Image.open(paths[i], \"r\")\n",
    "        plt.imshow(np.asarray(image))\n",
    "        plt.title(str(paths[i]).split(\"/\")[-2], color=\"white\")\n",
    "\n",
    "plot_images(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(category_counts.keys())\n",
    "(DATA_PATH.parent / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "(DATA_PATH.parent / \"test\").mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_PATH = DATA_PATH.parent / \"train\"\n",
    "TEST_PATH = DATA_PATH.parent / \"test\"\n",
    "BATCH_SIZE = 64\n",
    "INPUT_SHAPE = (64, 64, 3)\n",
    "CLASS_MODEL = \"categorical\"\n",
    "SEED = random.randint(1, 100000)\n",
    "SPLIT = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class subdirectories\n",
    "for label in category_counts.keys():\n",
    "    (TRAIN_PATH / label).mkdir(exist_ok=True)\n",
    "    (TEST_PATH / label).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = {}\n",
    "for category in category_counts.keys():\n",
    "    for image_path in (DATA_PATH / category).glob(\"*\"):\n",
    "        all_paths.update({image_path: category})\n",
    "\n",
    "X = pd.Series(list(all_paths.keys()))\n",
    "y = pd.get_dummies(pd.Series(all_paths.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_image_files() -> None:\n",
    "    \"\"\"\n",
    "    Move all training and test files to train and test directories in the data/eurosat directory.\n",
    "    \"\"\"\n",
    "    for train_index, test_index in SPLIT.split(X, y):\n",
    "        train_paths = X[train_index]\n",
    "        test_paths = X[test_index]\n",
    "\n",
    "        new_train_paths = [TRAIN_PATH / path.parent.name / path.name for path in train_paths]\n",
    "        new_test_paths = [TEST_PATH / path.parent.name / path.name for path in test_paths]\n",
    "        train_path_map = list((zip(train_paths, new_train_paths)))\n",
    "        test_path_map = list((zip(test_paths, new_test_paths)))\n",
    "\n",
    "        print(\"Moving training files to: {}\".format(TRAIN_PATH.as_posix()))\n",
    "        for paths in tqdm(train_path_map):\n",
    "            if not Path(TRAIN_PATH / paths[1]).exists():\n",
    "                shutil.copy(paths[0], paths[1])\n",
    "            else:\n",
    "                print(f\"Already copied: {paths}\")\n",
    "\n",
    "        print(\"Moving testing files to: {}\".format(TEST_PATH.as_posix()))\n",
    "        for paths in tqdm(test_path_map):\n",
    "            if not Path(TEST_PATH / paths[1]).exists():\n",
    "                shutil.copy(paths[0], paths[1])\n",
    "            else:\n",
    "                print(f\"Already copied: {paths}\")\n",
    "\n",
    "move_image_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True, \n",
    "    rotation_range=55,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=[0.2, 1],\n",
    "    validation_split=0.2,\n",
    ")\n",
    "train_generator = train_preprocessor.flow_from_directory(directory=TRAIN_PATH, target_size=(64, 64), batch_size=BATCH_SIZE, class_mode=CLASS_MODEL, subset=\"training\", shuffle=True, seed=SEED)\n",
    "validation_generator = train_preprocessor.flow_from_directory(directory=TRAIN_PATH, target_size=(64, 64), batch_size=BATCH_SIZE, class_mode=CLASS_MODEL, subset=\"validation\", shuffle=True, seed=SEED)\n",
    "\n",
    "test_preprocessor = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_preprocessor.flow_from_directory(directory=TEST_PATH, target_size=(64, 64), batch_size=BATCH_SIZE, class_mode=CLASS_MODEL, color_mode=\"rgb\", shuffle=False, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(str(img_paths[random.randint(0, len(img_paths)-1)]))\n",
    "\n",
    "plt.imshow(image[:, :, ::-1])\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.expand_dims(tf.keras.preprocessing.image.img_to_array(image), 0)\n",
    "iterator = train_preprocessor.flow(samples * 255, batch_size=1)\n",
    "\n",
    "figure, axis = plt.subplots(3, 3, figsize=(12, 12))\n",
    "figure.suptitle(\"Sample of training image transformations\")\n",
    "figure.set\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axis[i][j].imshow(next(iterator)[0].astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"class_indices\", train_generator.class_indices)\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try performing some transfer learning on this model\n",
    "base_model = ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=INPUT_SHAPE)\n",
    "model_head = base_model.output\n",
    "model_head = tf.keras.layers.Flatten()(model_head)\n",
    "model_head = tf.keras.layers.Dense(512, activation=\"selu\")(model_head)\n",
    "model_head = tf.keras.layers.Dropout(0.15)(model_head)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(model_head)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output_layer)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0004), loss=\"categorical_crossentropy\", metrics=[\"categorical_crossentropy\", \"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(history: T.Dict[str, T.Any]) -> None:\n",
    "    \"\"\"\n",
    "    Plot model history.\n",
    "    \"\"\"\n",
    "    acc = history.history['categorical_crossentropy']\n",
    "    val_acc = history.history['val_categorical_crossentropy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def display_results(y_true, y_preds, class_labels):\n",
    "    \n",
    "    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n",
    "                          columns=class_labels).T\n",
    "    results.rename(columns={0: 'Precision',\n",
    "                           1: 'Recall',\n",
    "                           2: 'F-Score',\n",
    "                           3: 'Support'}, inplace=True)\n",
    "    \n",
    "    conf_mat = pd.DataFrame(confusion_matrix(y_true, y_preds), \n",
    "                            columns=class_labels,\n",
    "                            index=class_labels)    \n",
    "    f2 = fbeta_score(y_true, y_preds, beta=2, average='micro')\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Global F2 Score: {f2}\")\n",
    "\n",
    "    return results, conf_mat\n",
    "\n",
    "def plot_predictions(y_true, y_preds, test_generator, class_indices):\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i, idx in enumerate(np.random.choice(test_generator.samples, size=20, replace=False)):\n",
    "        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(test_generator[idx]))\n",
    "        pred_idx = np.argmax(y_preds[idx])\n",
    "        true_idx = y_true[idx]\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        ax.set_title(\"{}\\n({})\".format(class_indices[pred_idx], class_indices[true_idx]),\n",
    "                     color=(\"green\" if pred_idx == true_idx else \"red\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = DATA_PATH / \"checkpoints\"\n",
    "N_STEPS = train_generator.samples//BATCH_SIZE\n",
    "N_VAL_STEPS = validation_generator.samples//BATCH_SIZE\n",
    "N_EPOCHS = 100\n",
    "\n",
    "# model callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='../working/model.weights.best.hdf5',\n",
    "                        monitor=\"acc\",\n",
    "                        save_best_only=True,\n",
    "                        verbose=1)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"acc\",\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='max')\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"acc\", factor=0.5,\n",
    "                              patience=3, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=N_STEPS, \n",
    "    epochs=50, \n",
    "    callbacks=[early_stop, checkpoint], \n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=N_VAL_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "predictions = model.predict(test_generator, steps=len(test_generator.filenames))\n",
    "predicted_classes = np.argmax(np.rint(predictions), axis=1)\n",
    "true_classes=test_generator.classes\n",
    "\n",
    "prf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\n",
    "prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "211bf73c8563a1dbaf67c8565265b14b92bce91a8d3fc768f8d1bcc63fc9272a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('aerial-segmentation-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
